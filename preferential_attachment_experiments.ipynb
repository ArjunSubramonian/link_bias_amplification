{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b45e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from os import environ\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import CitationFull, Coauthor, Twitch\n",
    "from gcn_conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, to_dense_adj, add_remaining_self_loops, degree, is_undirected\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b334570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "dataset_name = environ.get('dataset_name', 'Cora_ML')\n",
    "dataset_name = 'Physics'\n",
    "conv_type = environ.get('conv_type', 'sym')\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6780713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, conv_type):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels, hidden_channels, conv=conv_type)] + \\\n",
    "                                [GCNConv(hidden_channels, hidden_channels, conv=conv_type) for i in range(k - 2)] + \\\n",
    "                                [GCNConv(hidden_channels, out_channels, conv=conv_type)])\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        return self.convs[-1](x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return prob_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0e9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1cc1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    if dataset_name in [\"Cora\", \"Cora_ML\", \"CiteSeer\", \"PubMed\"]:\n",
    "        path = osp.join('.', 'data', 'CitationFull')\n",
    "        dataset = CitationFull(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"CS\", \"Physics\"]:\n",
    "        path = osp.join('.', 'data', 'Coauthor')\n",
    "        dataset = Coauthor(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"RU\"]:\n",
    "        path = osp.join('.', 'data', 'Twitch')\n",
    "        dataset = Twitch(path, name=\"RU\", transform=transform)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f377f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test: 0.9277\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.43 GiB (GPU 0; 11.91 GiB total capacity; 6.73 GiB already allocated; 3.29 GiB free; 7.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-376a0af02887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtaylor_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dense_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch_geometric/utils/to_dense_adj.py\u001b[0m in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mflattened_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_num_nodes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_num_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.43 GiB (GPU 0; 11.91 GiB total capacity; 6.73 GiB already allocated; 3.29 GiB free; 7.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "test_data = dataset[0][2]\n",
    "num_labels = int(test_data.y.max()) + 1\n",
    "\n",
    "# masks = []\n",
    "x_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "y_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "pcc_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "auc_list = []\n",
    "\n",
    "for seed_idx, seed in enumerate([34, 87, 120, 11, 93, 24, 25, 56, 49, 54]):\n",
    "    seed_everything(0)\n",
    "    \n",
    "    dataset = load_dataset(dataset_name)\n",
    "    train_data, val_data, test_data = dataset[0]\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    model = Net(dataset.num_features, 128, 64, conv_type).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_auc = final_test_auc = 0\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(model, train_data)\n",
    "        val_auc = test(model, val_data)\n",
    "        test_auc = test(model, test_data)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = test_auc\n",
    "#         if epoch % 20 == 0:\n",
    "#             print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "#                   f'Test: {test_auc:.4f}')\n",
    "\n",
    "    print(f'Final Test: {final_test_auc:.4f}')\n",
    "    auc_list.append(final_test_auc)\n",
    "    \n",
    "    model.eval()\n",
    "    rep = model.encode(test_data.x, test_data.edge_index)\n",
    "    final_probs = model.decode_all(rep).detach().cpu()\n",
    "    \n",
    "    label_adj = to_dense_adj(test_data.edge_label_index, max_num_nodes=test_data.x.size(0))[0]\n",
    "    intra_mask = (test_data.y.reshape(-1, 1) == test_data.y.reshape(1, -1)) & (label_adj == 1)\n",
    "#     masks.append(intra_mask)\n",
    "    \n",
    "#     U, _, V = torch.pca_lowrank(rep, q=2)\n",
    "#     rep_pca = U.detach().cpu().numpy()\n",
    "#     groups = test_data.y.cpu().numpy()\n",
    "#     for c in range(int(groups.max()) + 1):\n",
    "#         plt.scatter(rep_pca[:, 0][groups == c], rep_pca[:, 1][groups == c])\n",
    "#     plt.show()\n",
    "    \n",
    "    z = test_data.x\n",
    "    for conv in model.convs:\n",
    "        z = z @ conv.lin.weight.detach().t()\n",
    "\n",
    "    taylor_rep = torch.zeros_like(z)\n",
    "    adj = to_dense_adj(test_data.edge_index, max_num_nodes=test_data.x.size(0))[0]\n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = torch.nonzero(test_data.y.flatten() == c).flatten()\n",
    "        c_section = adj[c_mask.reshape(-1,1), c_mask]\n",
    "\n",
    "        deg_i = c_section.sum(dim=1)\n",
    "        deg_j = c_section.sum(dim=0)\n",
    "\n",
    "        if conv_type == \"sym\":\n",
    "            eigv_i = torch.sqrt(deg_i / deg_i.sum())\n",
    "            eigv_j = torch.sqrt(deg_j / deg_j.sum())\n",
    "        else:\n",
    "            eigv_i = torch.ones_like(deg_i)\n",
    "            eigv_j = deg_j / deg_j.sum()\n",
    "\n",
    "        taylor_rep[c_mask] = eigv_i.reshape(-1, 1) @ eigv_j.reshape(1, -1) @ z[c_mask]\n",
    "    \n",
    "    pred_probs = model.decode_all(taylor_rep).detach().cpu()\n",
    "#     y_idx = test_data.y.argsort()\n",
    "#     plot_probs = pred_probs[y_idx][:, y_idx]\n",
    "#     plot_mask = intra_mask[y_idx][:, y_idx]\n",
    "#     plot_probs[~plot_mask] = 0\n",
    "#     seaborn.heatmap(plot_probs.cpu().numpy())\n",
    "#     plt.show()\n",
    "\n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = ((test_data.y.reshape(-1, 1) == c) & (test_data.y.reshape(1, -1) == c)) & (label_adj == 1)\n",
    "        \n",
    "        x = final_probs[c_mask].flatten().numpy()\n",
    "        y = pred_probs[c_mask].flatten().numpy()\n",
    "        \n",
    "        if len(x) <= 1:\n",
    "            pcc = (0.0, 0.0)\n",
    "        else:\n",
    "            pcc = pearsonr(x, y)\n",
    "        pcc_list[c][seed_idx].append(pcc[0])\n",
    "\n",
    "#         plt.scatter(x, y)\n",
    "#         plt.xlabel('Actual link prediction score')\n",
    "#         plt.ylabel('Estimated link prediction score')\n",
    "#         plt.title(dataset.name + \", \" + r\"$r = {:.3f}$, \".format(pcc[0]) + r\"$p = {:.3f}$\".format(pcc[1]))\n",
    "#         plt.show()\n",
    "\n",
    "        x_list[c][seed_idx] = x.tolist()\n",
    "        y_list[c][seed_idx] = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da47019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = masks[0]\n",
    "# for t1 in masks[1:]:\n",
    "#     assert (t0 == t1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_all = torch.tensor(pcc_list)\n",
    "pcc_avg = pcc_all.mean().item()\n",
    "pcc_std = pcc_all.std().item()\n",
    "pcc_str = \"{0:.3f} ± \".format(pcc_avg) + \"{0:.3f}\".format(pcc_std)\n",
    "print(pcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5735374",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_all = torch.tensor(auc_list)\n",
    "auc_avg = auc_all.mean().item()\n",
    "auc_std = auc_all.std().item()\n",
    "auc_str = \"{0:.3f} ± \".format(auc_avg) + \"{0:.3f}\".format(auc_std)\n",
    "print(auc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79830dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_titles = [\"Actual link prediction score\", \"Estimated link prediction score\"]\n",
    "\n",
    "for idx, (a_list, b_list) in enumerate([(x_list, y_list), (y_list, x_list)]):\n",
    "    \n",
    "    plotly_objs = []\n",
    "    \n",
    "    min_avg = 0\n",
    "    max_avg = 0\n",
    "    \n",
    "    for c in range(len(a_list)):\n",
    "        \n",
    "        x_all = torch.tensor(a_list[c])\n",
    "        y_all = torch.tensor(b_list[c])\n",
    "        \n",
    "        if x_all.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(x_all)):\n",
    "            x, y = x_all[i], y_all[i]\n",
    "            rho, _, _, _ = np.linalg.lstsq(x.flatten().numpy()[:,np.newaxis], y.flatten().numpy())\n",
    "            y_all[i] /= rho[0]\n",
    "\n",
    "        x_avg = x_all.mean(dim=0)\n",
    "        y_avg = y_all.mean(dim=0)\n",
    "        \n",
    "        min_avg = min(min_avg, x_avg.min().item())\n",
    "        min_avg = min(min_avg, y_avg.min().item())\n",
    "        max_avg = max(max_avg, x_avg.max().item())\n",
    "        max_avg = max(max_avg, y_avg.max().item())\n",
    "\n",
    "        x_sort = torch.argsort(x_avg)\n",
    "        x_avg = x_avg[x_sort].tolist()\n",
    "\n",
    "        y_max = y_all.max(dim=0).values[x_sort].tolist()\n",
    "        y_min = y_all.min(dim=0).values[x_sort].tolist()\n",
    "        y_avg = y_avg[x_sort].tolist()\n",
    "        \n",
    "        plotly_objs.extend([\n",
    "            go.Scatter(\n",
    "                x=x_avg,\n",
    "                y=y_avg,\n",
    "                mode='markers',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                x=x_avg+x_avg[::-1], # x, then x reversed\n",
    "                y=y_max+y_min[::-1], # upper, then lower reversed\n",
    "                fill='toself',\n",
    "                fillcolor='rgba(0,100,80,0.2)',\n",
    "                line=dict(color='rgba(255,255,255,0)'),\n",
    "                hoverinfo=\"skip\",\n",
    "                showlegend=False\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    diag_y = [min_avg, max_avg]\n",
    "    diag_x = diag_y\n",
    "    \n",
    "    plotly_objs.append(go.Scatter(\n",
    "                x=diag_x,\n",
    "                y=diag_y,\n",
    "                mode='lines',\n",
    "                line={'dash': 'dash', 'color': 'black'},\n",
    "                showlegend=False\n",
    "            ))\n",
    "  \n",
    "    # avoid loading mathjax text\n",
    "    fig=px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])\n",
    "    fig.write_image(\"plots/{}_{}_{}.pdf\".format(dataset.name, idx, conv_type))\n",
    "    time.sleep(2)\n",
    "\n",
    "    if conv_type == \"sym\":\n",
    "        plot_title = r\"$\\Phi_s \\text{ on \" + dataset.name + r\", test AUC: }\" + auc_str + r\"$\"\n",
    "    else:\n",
    "        plot_title = r\"$\\Phi_r \\text{ on \" + dataset.name + r\"}$\"\n",
    "\n",
    "    fig = go.Figure(plotly_objs).update_layout(\n",
    "        xaxis_title=r\"$\\text{Average \" + axis_titles[idx].lower() + r\"}$\",\n",
    "        yaxis_title=r\"$\\text{\" + axis_titles[1 - idx] + r\"}$\"\n",
    "    )\n",
    "    fig.update_layout(title_text=plot_title, title_x=0.5)\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=30, b=20),\n",
    "    )\n",
    "    fig.add_annotation(dict(x=0.75,\n",
    "                            y=0.2,\n",
    "                            text=r\"$r = {}$\".format(pcc_str),\n",
    "                            showarrow=False,\n",
    "                            textangle=0,\n",
    "                            xanchor='left',\n",
    "                            xref=\"paper\",\n",
    "                            yref=\"paper\"))\n",
    "    fig.write_image(\"plots/{}_{}_{}.pdf\".format(dataset.name, idx, conv_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade44ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
