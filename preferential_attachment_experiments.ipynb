{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b45e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from os import environ\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import CitationFull, Coauthor, WebKB, LastFMAsia, Twitch\n",
    "from gcn_conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, to_dense_adj, add_remaining_self_loops, degree, is_undirected\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5af8805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./plots/\n",
      "./plots/pubmed_sym.pdf\n",
      "./plots/CS_sym.pdf\n",
      "./plots/EN_sym.pdf\n",
      "./plots/cora_sym.pdf\n",
      "./plots/citeseer_sym.pdf\n",
      "./plots/LastFMAsia_sym.pdf\n",
      "./plots/cora_ml_sym.pdf\n",
      "./plots/FR_sym.pdf\n",
      "./plots/DE_sym.pdf\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf plots.tar.gz ./plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb86198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "dataset_name = environ.get('dataset_name', 'Cora_ML')\n",
    "conv_type = environ.get('conv_type', 'sym')\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6780713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, conv_type):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels, hidden_channels, conv=conv_type)] + \\\n",
    "                                [GCNConv(hidden_channels, hidden_channels, conv=conv_type) for i in range(k - 2)] + \\\n",
    "                                [GCNConv(hidden_channels, out_channels, conv=conv_type)])\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        return self.convs[-1](x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return prob_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0e9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1bc45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    if dataset_name in [\"Cora\", \"Cora_ML\", \"CiteSeer\", \"PubMed\"]:\n",
    "        path = osp.join('.', 'data', 'CitationFull')\n",
    "        dataset = CitationFull(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"CS\", \"Physics\"]:\n",
    "        path = osp.join('.', 'data', 'Coauthor')\n",
    "        dataset = Coauthor(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in ['Cornell', 'Texas', 'Wisconsin']:\n",
    "        path = osp.join('.', 'data', 'WebKB')\n",
    "        dataset = WebKB(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"LastFMAsia\"]:\n",
    "        path = osp.join('.', 'data', 'LastFMAsia')\n",
    "        dataset = LastFMAsia(path, transform=transform)\n",
    "        dataset.name = \"LastFMAsia\"\n",
    "    elif dataset_name in [\"DE\", \"EN\", \"FR\"]:\n",
    "        path = osp.join('.', 'data', 'Twitch')\n",
    "        dataset = Twitch(path, name=dataset_name, transform=transform)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f377f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test: 0.9510\n",
      "Final Test: 0.9472\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8539b5fbfa7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbest_val_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_test_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f15352ed3268>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# We perform a new round of negative sampling for every training epoch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     neg_edge_index = negative_sampling(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py\u001b[0m in \u001b[0;36mnegative_sampling\u001b[0;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of tries to sample negative indices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneg_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch_geometric/utils/negative_sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(population, k, device)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mselected_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/random.py\u001b[0m in \u001b[0;36m_randbelow_with_getrandbits\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_randbelow_with_getrandbits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"Return a random int in the range [0,n).  Raises ValueError if n==0.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "test_data = dataset[0][2]\n",
    "num_labels = int(test_data.y.max()) + 1\n",
    "\n",
    "# masks = []\n",
    "x_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "y_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "pcc_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "auc_list = []\n",
    "\n",
    "for seed_idx, seed in enumerate([34, 87, 120, 11, 93, 24, 25, 56, 49, 54]):\n",
    "    seed_everything(0)\n",
    "    \n",
    "    dataset = load_dataset(dataset_name)\n",
    "    train_data, val_data, test_data = dataset[0]\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    model = Net(dataset.num_features, 128, 64, conv_type).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_auc = final_test_auc = 0\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(model, train_data)\n",
    "        val_auc = test(model, val_data)\n",
    "        test_auc = test(model, test_data)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = test_auc\n",
    "#         if epoch % 20 == 0:\n",
    "#             print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "#                   f'Test: {test_auc:.4f}')\n",
    "\n",
    "    print(f'Final Test: {final_test_auc:.4f}')\n",
    "    auc_list.append(final_test_auc)\n",
    "    \n",
    "    model.eval()\n",
    "    rep = model.encode(test_data.x, test_data.edge_index)\n",
    "    final_probs = model.decode_all(rep).detach().cpu()\n",
    "    \n",
    "    label_adj = to_dense_adj(test_data.edge_label_index, max_num_nodes=test_data.x.size(0))[0]\n",
    "    intra_mask = (test_data.y.reshape(-1, 1) == test_data.y.reshape(1, -1)) & (label_adj == 1)\n",
    "#     masks.append(intra_mask)\n",
    "    \n",
    "#     U, _, V = torch.pca_lowrank(rep, q=2)\n",
    "#     rep_pca = U.detach().cpu().numpy()\n",
    "#     groups = test_data.y.cpu().numpy()\n",
    "#     for c in range(int(groups.max()) + 1):\n",
    "#         plt.scatter(rep_pca[:, 0][groups == c], rep_pca[:, 1][groups == c])\n",
    "#     plt.show()\n",
    "    \n",
    "    z = test_data.x\n",
    "    for conv in model.convs:\n",
    "        z = z @ conv.lin.weight.detach().t()\n",
    "\n",
    "    taylor_rep = torch.zeros_like(z)\n",
    "    adj = to_dense_adj(test_data.edge_index, max_num_nodes=test_data.x.size(0))[0]\n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = torch.nonzero(test_data.y.flatten() == c).flatten()\n",
    "        c_section = adj[c_mask.reshape(-1,1), c_mask]\n",
    "\n",
    "        deg_i = c_section.sum(dim=1)\n",
    "        deg_j = c_section.sum(dim=0)\n",
    "\n",
    "        if conv_type == \"sym\":\n",
    "            eigv_i = torch.sqrt(deg_i / deg_i.sum())\n",
    "            eigv_j = torch.sqrt(deg_j / deg_j.sum())\n",
    "        else:\n",
    "            eigv_i = torch.ones_like(deg_i)\n",
    "            eigv_j = deg_j / deg_j.sum()\n",
    "\n",
    "        taylor_rep[c_mask] = eigv_i.reshape(-1, 1) @ eigv_j.reshape(1, -1) @ z[c_mask]\n",
    "    \n",
    "    pred_probs = model.decode_all(taylor_rep).detach().cpu()\n",
    "#     y_idx = test_data.y.argsort()\n",
    "#     plot_probs = pred_probs[y_idx][:, y_idx]\n",
    "#     plot_mask = intra_mask[y_idx][:, y_idx]\n",
    "#     plot_probs[~plot_mask] = 0\n",
    "#     seaborn.heatmap(plot_probs.cpu().numpy())\n",
    "#     plt.show()\n",
    "\n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = ((test_data.y.reshape(-1, 1) == c) & (test_data.y.reshape(1, -1) == c)) & (label_adj == 1)\n",
    "        \n",
    "        x = final_probs[c_mask].flatten().numpy()\n",
    "        y = pred_probs[c_mask].flatten().numpy()\n",
    "        \n",
    "        if len(x) <= 1:\n",
    "            pcc = (0.0, 0.0)\n",
    "        else:\n",
    "            pcc = pearsonr(x, y)\n",
    "        pcc_list[c][seed_idx].append(pcc[0])\n",
    "\n",
    "#         plt.scatter(x, y)\n",
    "#         plt.xlabel(r'$\\Phi_s$ link prediction score')\n",
    "#         plt.ylabel('Theoretic link prediction score')\n",
    "#         plt.title(dataset.name + \", \" + r\"$r = {:.3f}$, \".format(pcc[0]) + r\"$p = {:.3f}$\".format(pcc[1]))\n",
    "#         plt.show()\n",
    "\n",
    "        x_list[c][seed_idx] = x.tolist()\n",
    "        y_list[c][seed_idx] = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da47019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = masks[0]\n",
    "# for t1 in masks[1:]:\n",
    "#     assert (t0 == t1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_all = torch.tensor(pcc_list)\n",
    "pcc_avg = pcc_all.mean().item()\n",
    "pcc_std = pcc_all.std().item()\n",
    "pcc_str = \"{0:.3f} ± \".format(pcc_avg) + \"{0:.3f}\".format(pcc_std)\n",
    "print(pcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093dc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_all = torch.tensor(auc_list)\n",
    "auc_avg = auc_all.mean().item()\n",
    "auc_std = auc_all.std().item()\n",
    "auc_str = \"{0:.3f} ± \".format(auc_avg) + \"{0:.3f}\".format(auc_std)\n",
    "print(auc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79830dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_objs = []\n",
    "\n",
    "min_avg = 0\n",
    "max_avg = 0\n",
    "\n",
    "for c in range(len(x_list)):\n",
    "\n",
    "    x_all = torch.tensor(x_list[c])\n",
    "    y_all = torch.tensor(y_list[c])\n",
    "\n",
    "    if x_all.numel() == 0:\n",
    "        continue\n",
    "\n",
    "    for i in range(len(x_all)):\n",
    "        x, y = x_all[i], y_all[i]\n",
    "        rho, _, _, _ = np.linalg.lstsq(x.flatten().numpy()[:,np.newaxis], y.flatten().numpy())\n",
    "        y_all[i] /= rho[0]\n",
    "\n",
    "    x_avg = x_all.mean(dim=0)\n",
    "    y_avg = y_all.mean(dim=0)\n",
    "    \n",
    "    min_avg = min(min_avg, x_avg.min().item())\n",
    "    min_avg = min(min_avg, y_avg.min().item())\n",
    "    max_avg = max(max_avg, x_avg.max().item())\n",
    "    max_avg = max(max_avg, y_avg.max().item())\n",
    "    \n",
    "    x_range = x_all.max(dim=0).values - x_all.min(dim=0).values\n",
    "    y_range = y_all.max(dim=0).values - y_all.min(dim=0).values\n",
    "    marker_size = (0.1 * (x_range ** 2 + y_range ** 2)).tolist()\n",
    "\n",
    "    plotly_objs.extend([\n",
    "        go.Scatter(\n",
    "            x=x_avg.tolist(),\n",
    "            y=y_avg.tolist(),\n",
    "            mode='markers',\n",
    "            showlegend=False,\n",
    "            marker=dict(size=marker_size,\n",
    "                        sizemode='area',\n",
    "                        sizeref=2.*max(marker_size)/(30.**2))\n",
    "        )\n",
    "    ])\n",
    "\n",
    "diag_y = [min_avg, max_avg]\n",
    "diag_x = diag_y\n",
    "\n",
    "plotly_objs.append(go.Scatter(\n",
    "            x=diag_x,\n",
    "            y=diag_y,\n",
    "            mode='lines',\n",
    "            line={'dash': 'dash', 'color': 'black'},\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "# avoid loading mathjax text\n",
    "fig=px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])\n",
    "fig.write_image(\"plots/{}_{}.pdf\".format(dataset.name, conv_type))\n",
    "time.sleep(2)\n",
    "\n",
    "import re\n",
    "plot_title = \" \".join([w.upper() for w in re.split('_| ', dataset.name)])\n",
    "axis_titles = [r\"\\textrm{ link prediction score}$\", r\"$\\textrm{Theoretic link prediction score}$\"]\n",
    "auc_annot = r\"\\textrm{ test AUC} = \" + auc_str + r\"$\"\n",
    "if conv_type == \"sym\":\n",
    "    axis_titles[0] = r\"$\\Phi_s\" + axis_titles[0]\n",
    "    auc_annot = r\"$\\Phi_s\" + auc_annot\n",
    "else:\n",
    "    axis_titles[0] = r\"$\\Phi_r\" + axis_titles[0]\n",
    "    auc_annot = r\"$\\Phi_r\" + auc_annot\n",
    "\n",
    "fig = go.Figure(plotly_objs).update_layout(\n",
    "    xaxis_title=axis_titles[0],\n",
    "    yaxis_title=axis_titles[1]\n",
    ")\n",
    "fig.update_layout(title_text=plot_title, title_x=0.5)\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=30, b=20),\n",
    ")\n",
    "fig.add_annotation(dict(x=0.6,\n",
    "                        y=0.2,\n",
    "                        text=r\"$r = {}$\".format(pcc_str),\n",
    "                        showarrow=False,\n",
    "                        textangle=0,\n",
    "                        xanchor='left',\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "fig.add_annotation(dict(x=0.6,\n",
    "                        y=0.15,\n",
    "                        text=auc_annot,\n",
    "                        showarrow=False,\n",
    "                        textangle=0,\n",
    "                        xanchor='left',\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "fig.write_image(\"plots/{}_{}.pdf\".format(dataset.name, conv_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efeef70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
