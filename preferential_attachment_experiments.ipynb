{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ecde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from os import environ\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import CitationFull, Coauthor, WebKB, LastFMAsia, Twitch\n",
    "from gcn_conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, to_dense_adj, add_remaining_self_loops, is_undirected, dense_to_sparse, subgraph, contains_self_loops\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b1f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "dataset_name = environ.get('dataset_name', 'CiteSeer')\n",
    "conv_type = environ.get('conv_type', 'sym')\n",
    "k = 2\n",
    "seeds = [34, 87, 120, 11, 93, 24, 25, 56, 49, 54]\n",
    "inspect_deviations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, conv_type):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels, hidden_channels, conv=conv_type)] + \\\n",
    "                                [GCNConv(hidden_channels, hidden_channels, conv=conv_type) for i in range(k - 2)] + \\\n",
    "                                [GCNConv(hidden_channels, out_channels, conv=conv_type)])\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index).relu()\n",
    "        return self.convs[-1](x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return prob_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67109a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    if dataset_name in [\"Cora\", \"Cora_ML\", \"CiteSeer\", \"DBLP\", \"PubMed\"]:\n",
    "        path = osp.join('.', 'data', 'CitationFull')\n",
    "        dataset = CitationFull(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"CS\", \"Physics\"]:\n",
    "        path = osp.join('.', 'data', 'Coauthor')\n",
    "        dataset = Coauthor(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in ['Cornell', 'Texas', 'Wisconsin']:\n",
    "        path = osp.join('.', 'data', 'WebKB')\n",
    "        dataset = WebKB(path, name=dataset_name, transform=transform)\n",
    "    elif dataset_name in [\"LastFMAsia\"]:\n",
    "        path = osp.join('.', 'data', 'LastFMAsia')\n",
    "        dataset = LastFMAsia(path, transform=transform)\n",
    "        dataset.name = \"LastFMAsia\"\n",
    "    elif dataset_name in [\"DE\", \"EN\", \"FR\"]:\n",
    "        path = osp.join('.', 'data', 'Twitch')\n",
    "        dataset = Twitch(path, name=dataset_name, transform=transform)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:5' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "test_data = dataset[0][2]\n",
    "num_labels = int(test_data.y.max()) + 1\n",
    "\n",
    "x_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "y_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "pcc_list = [[[] for _ in range(10)] for _ in range(num_labels)]\n",
    "auc_list = []\n",
    "\n",
    "feat_sim_list = []\n",
    "deg_sim_list = []\n",
    "colors_list = []\n",
    "\n",
    "for seed_idx, seed in enumerate(seeds):\n",
    "    seed_everything(0)\n",
    "    \n",
    "    dataset = load_dataset(dataset_name)\n",
    "    train_data, val_data, test_data = dataset[0]\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    model = Net(dataset.num_features, 128, 64, conv_type).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_auc = final_test_auc = 0\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(model, train_data)\n",
    "        val_auc = test(model, val_data)\n",
    "        test_auc = test(model, test_data)\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            final_test_auc = test_auc\n",
    "\n",
    "    print(f'Final Test: {final_test_auc:.4f}')\n",
    "    auc_list.append(final_test_auc)\n",
    "    \n",
    "    model.eval()\n",
    "    rep = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "    z = test_data.x\n",
    "    for conv in model.convs:\n",
    "        z = z @ conv.lin.weight.detach().t()\n",
    "    taylor_rep = torch.zeros_like(z)\n",
    "    \n",
    "    test_edge_index = add_remaining_self_loops(test_data.edge_index, num_nodes=test_data.x.size(0))[0]\n",
    "    print(\"Is undirected?\", is_undirected(test_edge_index))\n",
    "    print(\"Contains self-loops?\", contains_self_loops(test_edge_index))\n",
    "    \n",
    "    if inspect_deviations:\n",
    "        feat_rep = torch.zeros_like(z)\n",
    "        deg_sim = torch.zeros((test_data.x.size(0), test_data.x.size(0))).to(device)\n",
    "    \n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = torch.nonzero(test_data.y.flatten() == c).flatten()\n",
    "        c_edge_index = subgraph(c_mask, test_edge_index, relabel_nodes=True, num_nodes=test_data.x.size(0))[0]\n",
    "        c_section = to_dense_adj(c_edge_index)[0]\n",
    "\n",
    "        deg_i = c_section.sum(dim=1)\n",
    "        deg_j = c_section.sum(dim=0)\n",
    "\n",
    "        if conv_type == \"sym\":\n",
    "            eigv_i = torch.sqrt(deg_i / deg_i.sum())\n",
    "            eigv_j = torch.sqrt(deg_j / deg_j.sum())\n",
    "        else:\n",
    "            eigv_i = torch.ones_like(deg_i)\n",
    "            eigv_j = deg_j / deg_j.sum()\n",
    "\n",
    "        taylor_rep[c_mask] = eigv_i.reshape(-1, 1) @ eigv_j.reshape(1, -1) @ z[c_mask]\n",
    "        \n",
    "        if inspect_deviations:\n",
    "            feat_rep[c_mask] = torch.sqrt(torch.ones_like(deg_i) / deg_i.sum()).reshape(-1, 1) @ eigv_j.reshape(1, -1) @ z[c_mask]\n",
    "            prod = torch.sqrt(deg_i.reshape(-1, 1) @ deg_j.reshape(1, -1))\n",
    "            for i, idx in enumerate(c_mask):\n",
    "                deg_sim[idx, c_mask] = prod[i]\n",
    "            \n",
    "    if inspect_deviations:\n",
    "        deg_sim = deg_sim.cpu()\n",
    "\n",
    "    for c in range(int(test_data.y.max()) + 1):\n",
    "        c_mask = torch.nonzero(test_data.y.flatten() == c).flatten()\n",
    "        c_edge_label_index = subgraph(c_mask, test_data.edge_label_index, num_nodes=test_data.x.size(0))[0]\n",
    "        \n",
    "        x = model.decode(rep, c_edge_label_index).detach().cpu().numpy()\n",
    "        y = model.decode(taylor_rep, c_edge_label_index).detach().cpu().numpy()\n",
    "        \n",
    "        if len(x) <= 1:\n",
    "            pcc = (0.0, 0.0)\n",
    "        else:\n",
    "            pcc = pearsonr(x, y)\n",
    "        pcc_list[c][seed_idx].append(pcc[0])\n",
    "\n",
    "        x_list[c][seed_idx] = x.tolist()\n",
    "        y_list[c][seed_idx] = y.tolist()\n",
    "\n",
    "        if inspect_deviations:\n",
    "            label_adj = to_dense_adj(test_data.edge_label_index, max_num_nodes=test_data.x.size(0))[0]\n",
    "            c_mask = ((test_data.y.reshape(-1, 1) == c) & (test_data.y.reshape(1, -1) == c)) & (label_adj == 1)\n",
    "            \n",
    "            rho, _, _, _ = np.linalg.lstsq(y[:,np.newaxis], x)\n",
    "            colors = (torch.tensor(x) - torch.tensor(y * rho[0])).numpy().tolist()\n",
    "            colors_list += colors\n",
    "\n",
    "            feat_sim = model.decode(feat_rep, c_edge_label_index).detach().cpu()\n",
    "            feat_sim_list += feat_sim.numpy().tolist()\n",
    "            deg_sim_list += deg_sim[c_mask].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd110b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inspect_deviations:\n",
    "    feat_sim_list = np.array(feat_sim_list)\n",
    "    deg_sim_list = np.array(deg_sim_list)\n",
    "    colors_list = np.abs(np.array(colors_list))\n",
    "\n",
    "    tau = np.percentile(colors_list, 0)\n",
    "\n",
    "    print(\"Feature Similarity - Deviation:\", spearmanr(feat_sim_list[colors_list > tau], colors_list[colors_list > tau])[0])\n",
    "    print(\"Degree Product - Deviation:\", spearmanr(deg_sim_list[colors_list > tau], colors_list[colors_list > tau])[0])\n",
    "\n",
    "    plt.scatter(feat_sim_list[colors_list > tau], colors_list[colors_list > tau])\n",
    "    plt.xlabel(\"Feature similarity\")\n",
    "    plt.ylabel(\"Absolute deviation\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(deg_sim_list[colors_list > tau], colors_list[colors_list > tau])\n",
    "    plt.xlabel(\"Degree product\")\n",
    "    plt.ylabel(\"Absolute deviation\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(feat_sim_list[colors_list > tau], deg_sim_list[colors_list > tau], c=colors_list[colors_list > tau])\n",
    "    plt.xlabel(\"Feature similarity\")\n",
    "    plt.ylabel(\"Degree product\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_all = torch.tensor(pcc_list)\n",
    "pcc_avg = pcc_all.mean().item()\n",
    "pcc_std = pcc_all.std().item()\n",
    "pcc_str = \"{0:.3f} ± \".format(pcc_avg) + \"{0:.3f}\".format(pcc_std)\n",
    "print(pcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_all = torch.tensor(auc_list)\n",
    "auc_avg = auc_all.mean().item()\n",
    "auc_std = auc_all.std().item()\n",
    "auc_str = \"{0:.3f} ± \".format(auc_avg) + \"{0:.3f}\".format(auc_std)\n",
    "print(auc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59be7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_objs = []\n",
    "\n",
    "min_avg = 0\n",
    "max_avg = 0\n",
    "\n",
    "for c in range(len(x_list)):\n",
    "\n",
    "    x_all = torch.tensor(x_list[c])\n",
    "    y_all = torch.tensor(y_list[c])\n",
    "\n",
    "    if x_all.numel() == 0:\n",
    "        continue\n",
    "\n",
    "    for i in range(len(x_all)):\n",
    "        x, y = x_all[i], y_all[i]\n",
    "        rho, _, _, _ = np.linalg.lstsq(y.flatten().numpy()[:,np.newaxis], x.flatten().numpy())\n",
    "        y_all[i] *= rho[0]\n",
    "\n",
    "    x_avg = x_all.mean(dim=0)\n",
    "    y_avg = y_all.mean(dim=0)\n",
    "    \n",
    "    min_avg = min(min_avg, x_avg.min().item())\n",
    "    min_avg = min(min_avg, y_avg.min().item())\n",
    "    max_avg = max(max_avg, x_avg.max().item())\n",
    "    max_avg = max(max_avg, y_avg.max().item())\n",
    "    \n",
    "    x_range = x_all.max(dim=0).values - x_all.min(dim=0).values\n",
    "    y_range = y_all.max(dim=0).values - y_all.min(dim=0).values\n",
    "    marker_size = (0.1 * (x_range ** 2 + y_range ** 2)).tolist()\n",
    "\n",
    "    plotly_objs.extend([\n",
    "        go.Scatter(\n",
    "            x=x_avg.tolist(),\n",
    "            y=y_avg.tolist(),\n",
    "            mode='markers',\n",
    "            showlegend=False,\n",
    "            marker=dict(size=marker_size,\n",
    "                        sizemode='area',\n",
    "                        sizeref=2.*max(marker_size)/(30.**2))\n",
    "        )\n",
    "    ])\n",
    "\n",
    "diag_y = [min_avg, max_avg]\n",
    "diag_x = diag_y\n",
    "\n",
    "plotly_objs.append(go.Scatter(\n",
    "            x=diag_x,\n",
    "            y=diag_y,\n",
    "            mode='lines',\n",
    "            line={'dash': 'dash', 'color': 'black'},\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "# avoid loading mathjax text\n",
    "fig=px.scatter(x=[0, 1, 2, 3, 4], y=[0, 1, 4, 9, 16])\n",
    "fig.write_image(\"plots/{}_{}_{}.png\".format(dataset.name, conv_type, k))\n",
    "time.sleep(2)\n",
    "\n",
    "import re\n",
    "plot_title = \" \".join([w.upper() for w in re.split('_| ', dataset.name)])\n",
    "axis_titles = [r\"\\textrm{ link prediction score}$\", r\"$\\textrm{Theoretic link prediction score}$\"]\n",
    "auc_annot = r\"\\textrm{ test AUC} = \" + auc_str + r\"$\"\n",
    "if conv_type == \"sym\":\n",
    "    axis_titles[0] = r\"$\\Phi_s\" + axis_titles[0]\n",
    "    auc_annot = r\"$\\Phi_s\" + auc_annot\n",
    "else:\n",
    "    axis_titles[0] = r\"$\\Phi_r\" + axis_titles[0]\n",
    "    auc_annot = r\"$\\Phi_r\" + auc_annot\n",
    "\n",
    "fig = go.Figure(plotly_objs).update_layout(\n",
    "    xaxis_title=axis_titles[0],\n",
    "    yaxis_title=axis_titles[1]\n",
    ")\n",
    "fig.update_layout(title_text=plot_title, title_x=0.5)\n",
    "fig.update_layout(\n",
    "    margin=dict(l=20, r=20, t=30, b=20),\n",
    ")\n",
    "fig.add_annotation(dict(x=0.6,\n",
    "                        y=0.2,\n",
    "                        text=r\"$r = {}$\".format(pcc_str),\n",
    "                        showarrow=False,\n",
    "                        textangle=0,\n",
    "                        xanchor='left',\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "fig.add_annotation(dict(x=0.6,\n",
    "                        y=0.15,\n",
    "                        text=auc_annot,\n",
    "                        showarrow=False,\n",
    "                        textangle=0,\n",
    "                        xanchor='left',\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "fig.write_image(\"plots/{}_{}_{}.png\".format(dataset.name, conv_type, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cedcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f363a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
